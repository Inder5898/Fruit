{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredBinarySem6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaiAAKC5D0pInuOKN0q2B4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryap175/Orange-Fruit-Prediction/blob/main/PredBinarySem6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uts9lklpTLu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34bd276-b160-4eb1-b6ff-d47835a22cb7"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3inrHfnjTAeV"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn05rnEoUOPh"
      },
      "source": [
        "Load and Read From Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbN_5_uLTWGz"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255, \n",
        "        rotation_range=30,  \n",
        "        zoom_range = 0.15,\n",
        "        shear_range = 0.2,    \n",
        "        horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory( r'/content/drive/MyDrive/New Orange Images Dataset/Orange training',\n",
        "                                                  target_size=(64,64),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "val_set = val_datagen.flow_from_directory( r'/content/drive/MyDrive/New Orange Images Dataset/orange testing',\n",
        "                                          target_size=(64,64),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaRMqknwTbkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c57a1e2-172c-4921-a3a9-952009ef2802"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.BatchNormalization())\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#------------------------------ VGG19 ----------------------------------------------------\n",
        "Base_model = tf.keras.applications.VGG19(input_shape=[64, 64, 3],\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')\n",
        "Base_model.trainable = True\n",
        "model = tf.keras.Sequential([Base_model,\n",
        "                             keras.layers.GlobalAveragePooling2D(),\n",
        "                             keras.layers.Dense(64, activation='relu'),\n",
        "                             keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#------------------------------ MobileNetV2 ----------------------------------------------------\n",
        "Base_model = tf.keras.applications.MobileNetV2(input_shape=[64, 64, 3],\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')\n",
        "Base_model.trainable = False\n",
        "model1 = tf.keras.Sequential([Base_model,\n",
        "                             keras.layers.GlobalAveragePooling2D(),\n",
        "                             keras.layers.Dense(64, activation='relu'),\n",
        "                             keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "#------------------------------ LeNet ----------------------------------------------------\n",
        "cnn2 = tf.keras.models.Sequential()\n",
        "\n",
        "cnn2.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\", input_shape=[64, 64, 3]))\n",
        "cnn2.add(tf.keras.layers.BatchNormalization())\n",
        "cnn2.add(tf.keras.layers.AvgPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "\n",
        "cnn2.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\"))\n",
        "cnn2.add(tf.keras.layers.AvgPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "\n",
        "cnn2.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\"))\n",
        "\n",
        "cnn2.add(tf.keras.layers.Flatten())\n",
        "\n",
        "cnn2.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "cnn2.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "cnn2.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "cnn2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYnRNp5nTet6"
      },
      "source": [
        "\n",
        "print(\"--------------------------------------------VGG---------------------------------------------------\")\n",
        "vgg = model.fit(\n",
        "          training_set,\n",
        "          steps_per_epoch=15,\n",
        "          epochs=25,\n",
        "          validation_data = val_set,\n",
        "          validation_steps=10\n",
        "         )\n",
        "print(\"-------------------------------------------Mobile--------------------------------------------------\")\n",
        "mobile = model1.fit(\n",
        "          training_set,\n",
        "          steps_per_epoch=15,\n",
        "          epochs=25, \n",
        "          validation_data = val_set,\n",
        "          validation_steps=10\n",
        "         )\n",
        "print(\"---------------------------------------------CNN---------------------------------------------------\")\n",
        "history = cnn.fit(\n",
        "          training_set,\n",
        "          steps_per_epoch=15,\n",
        "          epochs=25, \n",
        "          validation_data = val_set,\n",
        "          validation_steps=10\n",
        "        )\n",
        "print(\"---------------------------------------------LeNet-----------------------------------------------\")\n",
        "history2 = cnn2.fit(\n",
        "          training_set,\n",
        "          steps_per_epoch=15,\n",
        "          epochs=25, \n",
        "          validation_data = val_set,\n",
        "          validation_steps=10\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3wJRbXRTiY-"
      },
      "source": [
        "epochs = 25\n",
        "acc = vgg.history['accuracy']\n",
        "val_acc = vgg.history['val_accuracy']\n",
        "loss = vgg.history['loss']\n",
        "val_loss = vgg.history['val_loss']\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Testing Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('vgg Working Accuracay')\n",
        "plt.show()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('vgg Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Testing Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(' cnn Working Accuracay')\n",
        "plt.show()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('cnn Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "acc = mobile.history['accuracy']\n",
        "val_acc = mobile.history['val_accuracy']\n",
        "loss=mobile.history['loss']\n",
        "val_loss = mobile.history['val_loss']\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Testing Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(' MobileNet Working Accuracay')\n",
        "plt.show()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('MobileNetv2 Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "acc = history2.history['accuracy']\n",
        "val_acc = history2.history['val_accuracy']\n",
        "loss=history2.history['loss']\n",
        "val_loss=history2.history['val_loss']\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Testing Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(' LeNet Working Accuracay')\n",
        "plt.show()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('LeNet Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD4c6-4CT9kq"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "p=r\"/content/drive/MyDrive/New Orange Images Dataset/orange testing/Oranges/3cbfec1259635898efae5b57ea3ddea3.jpg\"\n",
        "test_image = image.load_img(p, target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "test_image/=255.0\n",
        "result = cnn.predict(test_image)\n",
        "print(\"---- By CNN ----\")\n",
        "if result<0.5:\n",
        "  print('Selected Fruit is Orange') \n",
        "else:\n",
        "  print('Selected Fruit is Other than Orange')\n",
        "\n",
        "result_vgg = model.predict(test_image)\n",
        "print(\"---- By VGG ----\")\n",
        "if result_vgg<0.5:\n",
        "  print('Selected Fruit is Orange') \n",
        "else:\n",
        "  print('Selected Fruit is Other than Orange')\n",
        "\n",
        "result_mobile = model1.predict(test_image)\n",
        "print(\"---- By MobileNet ----\")\n",
        "if result_mobile<0.5:\n",
        "  print('Selected Fruit is Orange') \n",
        "else:\n",
        "  print('Selected Fruit is Other than Orange')\n",
        "\n",
        "result_lenet = cnn2.predict(test_image)\n",
        "print(\"---- By LeNet ----\")\n",
        "if result_lenet<0.5:\n",
        "  print('Selected Fruit is Orange') \n",
        "else:\n",
        "  print('Selected Fruit is Other than Orange')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4UL9h-kUCfn"
      },
      "source": [
        "def show(pred,img):\n",
        "\n",
        "  if pred<0.5: str = 'Selected Fruit is Orange'\n",
        "  else: str = 'Selected Fruit is Other than Orange'\n",
        "\n",
        "  plt.imshow(img)\n",
        "  plt.axis('on')\n",
        "  plt.title(str)\n",
        "  plt.show()\n",
        "\n",
        "img = image.load_img(p)\n",
        "print(\"------ CNN ------\")\n",
        "show(result,img)\n",
        "print(\"------ VGG-19 ------\")\n",
        "show(result_vgg,img)\n",
        "print(\"------ MobileNet_V2 ------\")\n",
        "show(result_mobile,img)\n",
        "print(\"------ LeNet ------\")\n",
        "show(result_lenet,img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ8oEL_ngYXf"
      },
      "source": [
        "'''#----------------------------------------Save Weight------------------------------------\n",
        "m_json = cnn.to_json()  \n",
        "with open(\"/content/drive/MyDrive/cnn.json\", \"w\") as json_file:  \n",
        "    json_file.write(m_json)  \n",
        "cnn.save_weights(\"/content/drive/MyDrive/Orange_Fruit_Weights_cnn.h5\")\n",
        "\n",
        "#-----------------------vgg-----------------\n",
        "m_json = model.to_json()  \n",
        "with open(\"/content/drive/MyDrive/vgg.json\", \"w\") as json_file:  \n",
        "    json_file.write(m_json)  \n",
        "model.save_weights(\"/content/drive/MyDrive/Orange_Fruit_Weights_vgg.h5\")\n",
        "#-----------------------mobilenet----------\n",
        "m_json = model1.to_json()  \n",
        "with open(\"/content/drive/MyDrive/mobile.json\", \"w\") as json_file:  \n",
        "    json_file.write(m_json)  \n",
        "model1.save_weights(\"/content/drive/MyDrive/Orange_Fruit_Weights_mobile.h5\")\n",
        "#-----------------------Lenet--------------\n",
        "m_json = cnn2.to_json()  \n",
        "with open(\"/content/drive/MyDrive/lenet.json\", \"w\") as json_file:  \n",
        "    json_file.write(m_json)  \n",
        "cnn2.save_weights(\"/content/drive/MyDrive/Orange_Fruit_Weights_lenet.h5\")'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}